{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from Data_Preprocessing import Load_Downsize_SaveAsH5 as cvt\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.losses import categorical_crossentropy\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### partial data with Top as target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = './data/'\n",
    "features = ['j_index','j1_phirel','j1_etarel','j1_phirot','j1_etarot','j1_deltaR','j1_pdgid','j1_pt','j1_ptrel','j1_erel'] \n",
    "labels = ['j_g','j_q','j_w','j_z','j_t']\n",
    "ratio=[.25,.25,.25,.25,1]\n",
    "size=2000\n",
    "seed=42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvt.LoadTransSave(filePath,features, labels,size=size,seed=seed,ratio=ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = dict(zip(features+['constituents_index'], [i for i in range(len(features)+1)]))\n",
    "\n",
    "features_list = ['j1_ptrel','j1_etarot','j1_phirot','j1_phirel','j1_etarel','j1_erel','j1_deltaR','j1_pdgid']\n",
    "\n",
    "def h5_to_data(h5path):\n",
    "    Data = {'mask':[], 'points':[], 'features':[],'label':[]}\n",
    "    f = h5py.File(h5path,'r')\n",
    "    raw_data = np.array([f[col][()] for col in cols])\n",
    "    label_arr = f['label'][()]\n",
    "    raw_data = raw_data.transpose((1,0))\n",
    "    mask, features, points = np.zeros((100,1)), np.zeros((100,len(features_list))), np.zeros((100,2)) # prepare constituents list\n",
    "    for i in range(len(raw_data)):\n",
    "        cIndex = int(raw_data[i][cols['constituents_index']])\n",
    "        if cIndex >= 100:                                               # skip when excess 100 particles\n",
    "            continue\n",
    "        \n",
    "        mask[cIndex] = [1]                                             # no mask for now\n",
    "        points[cIndex] = np.array([raw_data[i][cols['j1_etarel']],raw_data[i][cols['j1_phirel']]])\n",
    "        features[cIndex] = np.array([raw_data[i][cols[feat]] for feat in features_list])\n",
    "                \n",
    "        if i < len(raw_data)-1:\n",
    "            if raw_data[i][cols['j_index']] != raw_data[i+1][cols['j_index']] : # save the jet before switch to another\n",
    "                Data['mask'].append(mask)\n",
    "                Data['points'].append(points)\n",
    "                Data['features'].append(features)\n",
    "                Data['label'].append(label_arr[i])\n",
    "                mask, features, points = np.zeros((100,1)), np.zeros((100,len(features_list))), np.zeros((100,2))  \n",
    "    f.close()\n",
    "    y = Data.pop('label')\n",
    "    return Data, y\n",
    "\n",
    "def merging(gg,qq):\n",
    "    total={}\n",
    "    total['mask']=gg[\"mask\"]+qq[\"mask\"]\n",
    "    total['features']=gg[\"features\"]+qq[\"features\"]\n",
    "    total['points']=gg['points']+qq['points']\n",
    "    return total\n",
    "\n",
    "def separatedata(Data,y,rateval,ratetest):\n",
    "    features_train, features_test, features_val={},{},{}\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    mask = Data[\"mask\"]\n",
    "    features = Data[\"features\"]\n",
    "    points = Data[\"points\"]\n",
    "    X_ind = [i for i in range(len(y))]\n",
    "    X_train, X_ind, y_train, y_ind = train_test_split(X_ind, y, test_size=rateval+ratetest)\n",
    "    N=int(len(X_ind)*rateval/(rateval+ratetest))\n",
    "    X_val, X_test = X_ind[:N], X_ind[N:]\n",
    "    y_val, y_test = y_ind[:N], y_ind[N:]\n",
    "    \n",
    "    features_train['mask']=np.array([mask[i] for i in X_train])\n",
    "    features_train['features']=np.array([features[i] for i in X_train])\n",
    "    features_train['points']=np.array([points[i] for i in X_train])\n",
    "    \n",
    "    features_test['mask']=np.array([mask[i] for i in X_test])\n",
    "    features_test['features']=np.array([features[i] for i in X_test])\n",
    "    features_test['points']=np.array([points[i] for i in X_test])\n",
    "    \n",
    "    features_val['mask']=np.array([mask[i] for i in X_val])\n",
    "    features_val['features']=np.array([features[i] for i in X_val])\n",
    "    features_val['points']=np.array([points[i] for i in X_val])\n",
    "    \n",
    "    return features_train, features_val, features_test,np.array(y_train), np.array(y_val), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check shape:  (100, 1) (100, 2) (100, 8)\n"
     ]
    }
   ],
   "source": [
    "h5Path = \"data/data_2000jets_5labels_unbalanced.h5\"\n",
    "Data,y = h5_to_data(h5Path)\n",
    "print(\"check shape: \",Data['mask'][0].shape,Data['points'][0].shape,Data['features'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = separatedata(Data,y,0.25,0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'models')\n",
    "from tf_keras_model import get_particle_net_lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shapes={'points': X_train['points'][0].shape, 'features': X_train['features'][0].shape, 'mask': X_train['mask'][0].shape}\n",
    "num_classes = 2\n",
    "model = get_particle_net_lite(num_classes, input_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ParticleNet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "points (InputLayer)             [(None, 100, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "features (InputLayer)           [(None, 100, 8)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_transpose (TensorFl [(None, 2, 100)]     0           points[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims (TensorF [(None, 100, 1, 8)]  0           features[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul (TensorFlowOpLa [(None, 100, 2)]     0           points[0][0]                     \n",
      "                                                                 points[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_MatMul (TensorFlowO [(None, 100, 100)]   0           points[0][0]                     \n",
      "                                                                 tf_op_layer_transpose[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul_1 (TensorFlowOp [(None, 100, 2)]     0           points[0][0]                     \n",
      "                                                                 points[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_fts_bn (BatchNormal (None, 100, 1, 8)    32          tf_op_layer_ExpandDims[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum (TensorFlowOpLa [(None, 100, 1)]     0           tf_op_layer_mul[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul_2 (TensorFlowOp [(None, 100, 100)]   0           tf_op_layer_MatMul[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_1 (TensorFlowOp [(None, 100, 1)]     0           tf_op_layer_mul_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze (TensorFlow [(None, 100, 8)]     0           ParticleNet_fts_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub (TensorFlowOpLa [(None, 100, 100)]   0           tf_op_layer_Sum[0][0]            \n",
      "                                                                 tf_op_layer_mul_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_transpose_1 (Tensor [(None, 1, 100)]     0           tf_op_layer_Sum_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(3,)]               0           tf_op_layer_Squeeze[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add (TensorFlowOpLa [(None, 100, 100)]   0           tf_op_layer_sub[0][0]            \n",
      "                                                                 tf_op_layer_transpose_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [()]                 0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Neg (TensorFlowOpLa [(None, 100, 100)]   0           tf_op_layer_add[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_range (TensorFlowOp [(None,)]            0           tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_TopKV2 (TensorFlowO [(None, 100, 8), (No 0           tf_op_layer_Neg[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, 1, 1, 1)]    0           tf_op_layer_range[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 100, 7)]     0           tf_op_layer_TopKV2[0][1]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile (TensorFlowOpL [(None, 100, 7, 1)]  0           tf_op_layer_Reshape[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_1 (Tenso [(None, 100, 7, 1)]  0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_2 (Tenso [(None, 100, 1, 8)]  0           tf_op_layer_Squeeze[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat (TensorFlowO [(None, 100, 7, 2)]  0           tf_op_layer_Tile[0][0]           \n",
      "                                                                 tf_op_layer_ExpandDims_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile_1 (TensorFlowO [(None, 100, 7, 8)]  0           tf_op_layer_ExpandDims_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherNd (TensorFlo [(None, 100, 7, 8)]  0           tf_op_layer_Squeeze[0][0]        \n",
      "                                                                 tf_op_layer_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_1 (TensorFlowOp [(None, 100, 7, 8)]  0           tf_op_layer_GatherNd[0][0]       \n",
      "                                                                 tf_op_layer_Tile_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_1 (TensorFlo [(None, 100, 7, 16)] 0           tf_op_layer_Tile_1[0][0]         \n",
      "                                                                 tf_op_layer_Sub_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_conv0 (Co (None, 100, 7, 32)   512         tf_op_layer_concat_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_bn0 (Batc (None, 100, 7, 32)   128         ParticleNet_EdgeConv0_conv0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_act0 (Act (None, 100, 7, 32)   0           ParticleNet_EdgeConv0_bn0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_conv1 (Co (None, 100, 7, 32)   1024        ParticleNet_EdgeConv0_act0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_bn1 (Batc (None, 100, 7, 32)   128         ParticleNet_EdgeConv0_conv1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_act1 (Act (None, 100, 7, 32)   0           ParticleNet_EdgeConv0_bn1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_3 (Tenso [(None, 100, 1, 8)]  0           tf_op_layer_Squeeze[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_conv2 (Co (None, 100, 7, 32)   1024        ParticleNet_EdgeConv0_act1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_sc_conv ( (None, 100, 1, 32)   256         tf_op_layer_ExpandDims_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_bn2 (Batc (None, 100, 7, 32)   128         ParticleNet_EdgeConv0_conv2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_sc_bn (Ba (None, 100, 1, 32)   128         ParticleNet_EdgeConv0_sc_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_act2 (Act (None, 100, 7, 32)   0           ParticleNet_EdgeConv0_bn2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_transpose_2 (Tensor [(None, 2, 100)]     0           points[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze_1 (TensorFl [(None, 100, 32)]    0           ParticleNet_EdgeConv0_sc_bn[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean (TensorFlowOpL [(None, 100, 32)]    0           ParticleNet_EdgeConv0_act2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul_3 (TensorFlowOp [(None, 100, 2)]     0           points[0][0]                     \n",
      "                                                                 points[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_MatMul_1 (TensorFlo [(None, 100, 100)]   0           points[0][0]                     \n",
      "                                                                 tf_op_layer_transpose_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul_4 (TensorFlowOp [(None, 100, 2)]     0           points[0][0]                     \n",
      "                                                                 points[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_1 (TensorFlowOp [(None, 100, 32)]    0           tf_op_layer_Squeeze_1[0][0]      \n",
      "                                                                 tf_op_layer_Mean[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_2 (TensorFlowOp [(None, 100, 1)]     0           tf_op_layer_mul_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul_5 (TensorFlowOp [(None, 100, 100)]   0           tf_op_layer_MatMul_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_3 (TensorFlowOp [(None, 100, 1)]     0           tf_op_layer_mul_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_sc_act (A (None, 100, 32)      0           tf_op_layer_add_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub_2 (TensorFlowOp [(None, 100, 100)]   0           tf_op_layer_Sum_2[0][0]          \n",
      "                                                                 tf_op_layer_mul_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_transpose_3 (Tensor [(None, 1, 100)]     0           tf_op_layer_Sum_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_1 (TensorFlow [(3,)]               0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_2 (TensorFlowOp [(None, 100, 100)]   0           tf_op_layer_sub_2[0][0]          \n",
      "                                                                 tf_op_layer_transpose_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [()]                 0           tf_op_layer_Shape_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Neg_1 (TensorFlowOp [(None, 100, 100)]   0           tf_op_layer_add_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_range_1 (TensorFlow [(None,)]            0           tf_op_layer_strided_slice_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_TopKV2_1 (TensorFlo [(None, 100, 8), (No 0           tf_op_layer_Neg_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (TensorFl [(None, 1, 1, 1)]    0           tf_op_layer_range_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [(None, 100, 7)]     0           tf_op_layer_TopKV2_1[0][1]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile_2 (TensorFlowO [(None, 100, 7, 1)]  0           tf_op_layer_Reshape_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_4 (Tenso [(None, 100, 7, 1)]  0           tf_op_layer_strided_slice_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_5 (Tenso [(None, 100, 1, 32)] 0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_2 (TensorFlo [(None, 100, 7, 2)]  0           tf_op_layer_Tile_2[0][0]         \n",
      "                                                                 tf_op_layer_ExpandDims_4[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile_3 (TensorFlowO [(None, 100, 7, 32)] 0           tf_op_layer_ExpandDims_5[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherNd_1 (TensorF [(None, 100, 7, 32)] 0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "                                                                 tf_op_layer_concat_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_3 (TensorFlowOp [(None, 100, 7, 32)] 0           tf_op_layer_GatherNd_1[0][0]     \n",
      "                                                                 tf_op_layer_Tile_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_3 (TensorFlo [(None, 100, 7, 64)] 0           tf_op_layer_Tile_3[0][0]         \n",
      "                                                                 tf_op_layer_Sub_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_conv0 (Co (None, 100, 7, 64)   4096        tf_op_layer_concat_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_bn0 (Batc (None, 100, 7, 64)   256         ParticleNet_EdgeConv1_conv0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_act0 (Act (None, 100, 7, 64)   0           ParticleNet_EdgeConv1_bn0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_conv1 (Co (None, 100, 7, 64)   4096        ParticleNet_EdgeConv1_act0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_bn1 (Batc (None, 100, 7, 64)   256         ParticleNet_EdgeConv1_conv1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_act1 (Act (None, 100, 7, 64)   0           ParticleNet_EdgeConv1_bn1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_6 (Tenso [(None, 100, 1, 32)] 0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_conv2 (Co (None, 100, 7, 64)   4096        ParticleNet_EdgeConv1_act1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_sc_conv ( (None, 100, 1, 64)   2048        tf_op_layer_ExpandDims_6[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_bn2 (Batc (None, 100, 7, 64)   256         ParticleNet_EdgeConv1_conv2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_sc_bn (Ba (None, 100, 1, 64)   256         ParticleNet_EdgeConv1_sc_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_act2 (Act (None, 100, 7, 64)   0           ParticleNet_EdgeConv1_bn2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze_2 (TensorFl [(None, 100, 64)]    0           ParticleNet_EdgeConv1_sc_bn[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_1 (TensorFlowO [(None, 100, 64)]    0           ParticleNet_EdgeConv1_act2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_3 (TensorFlowOp [(None, 100, 64)]    0           tf_op_layer_Squeeze_2[0][0]      \n",
      "                                                                 tf_op_layer_Mean_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_sc_act (A (None, 100, 64)      0           tf_op_layer_add_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "mask (InputLayer)               [(None, 100, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_6 (TensorFlowOp [(None, 100, 64)]    0           ParticleNet_EdgeConv1_sc_act[0][0\n",
      "                                                                 mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_2 (TensorFlowO [(None, 64)]         0           tf_op_layer_Mul_6[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          8320        tf_op_layer_Mean_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            258         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 27,298\n",
      "Trainable params: 26,514\n",
      "Non-trainable params: 784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam(lr=1e-4)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1821 samples, validate on 911 samples\n",
      "Epoch 1/100\n",
      "1821/1821 [==============================] - 13s 7ms/sample - loss: 0.7955 - accuracy: 0.5080 - val_loss: 0.7951 - val_accuracy: 0.5247\n",
      "Epoch 2/100\n",
      "1821/1821 [==============================] - 8s 4ms/sample - loss: 0.7685 - accuracy: 0.5091 - val_loss: 0.7426 - val_accuracy: 0.5247\n",
      "Epoch 3/100\n",
      "1821/1821 [==============================] - 8s 4ms/sample - loss: 0.7511 - accuracy: 0.5096 - val_loss: 0.7235 - val_accuracy: 0.5247\n",
      "Epoch 4/100\n",
      "1821/1821 [==============================] - 8s 4ms/sample - loss: 0.7360 - accuracy: 0.5102 - val_loss: 0.7134 - val_accuracy: 0.5247\n",
      "Epoch 5/100\n",
      "1821/1821 [==============================] - 8s 4ms/sample - loss: 0.7159 - accuracy: 0.5184 - val_loss: 0.7071 - val_accuracy: 0.5247\n",
      "Epoch 6/100\n",
      "1821/1821 [==============================] - 8s 4ms/sample - loss: 0.6981 - accuracy: 0.5277 - val_loss: 0.7028 - val_accuracy: 0.5247\n",
      "Epoch 7/100\n",
      "1024/1821 [===============>..............] - ETA: 3s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-61ada2295b16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m           shuffle=True)\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Anacoda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mD:\\Softwares\\Anacoda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Anacoda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Anacoda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Anacoda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Anacoda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Anacoda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Anacoda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Anacoda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Anacoda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mD:\\Softwares\\Anacoda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train ,y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs, \n",
    "          validation_data=(X_val, y_val),\n",
    "          shuffle=True)\n",
    "model.evaluate(X_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = model.predict(X_test)\n",
    "predict_test = predict_test.transpose((1,0))\n",
    "# y_test = y_test.transpose((1,0))\n",
    "labels = ['t','not-t']\n",
    "df = pd.DataFrame()\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "auc1 = {}\n",
    "plt.figure()       \n",
    "for i, label in enumerate(labels):\n",
    "    df[label] = y_test[i]\n",
    "    df[label + '_pred'] = predict_test[i]\n",
    "    fpr[label], tpr[label], threshold = roc_curve(df[label],df[label+'_pred'])\n",
    "    auc1[label] = auc(fpr[label], tpr[label])\n",
    "    plt.plot(tpr[label],fpr[label],label='%s tagger, AUC = %.1f%%'%(label.replace('j_',''),auc1[label]*100.))\n",
    "plt.semilogy()\n",
    "plt.xlabel(\"Signal Efficiency\")\n",
    "plt.ylabel(\"Background Efficiency\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.ylim(0.001,1)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.figtext(0.25, 0.90,'Particle_lite',fontweight='bold', wrap=True, horizontalalignment='right', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(history.history['loss'], linewidth=1)\n",
    "plt.plot(history.history['val_loss'], linewidth=1)\n",
    "plt.title('Loss of Particle-lite')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['training sample loss','validation sample loss'])\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
