{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import os\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsize(df,size,seed,labels):\n",
    "    jet_dict = {}\n",
    "    np.random.seed(seed)\n",
    "    for label in labels:\n",
    "        jet_dict[label] = np.random.choice(a=df[df[label]==1].j_index, size=size,replace=False )\n",
    "    mini_df = pd.DataFrame()\n",
    "    for label in labels:\n",
    "        mini_df = pd.concat([mini_df,df[df.j_index.isin(jet_dict[label])]],axis=0)\n",
    "    return mini_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsize_unbalanced(df,max_size,seed,labels,ratio):\n",
    "    '''max_size is the baseline. It is 1 in ratio.'''\n",
    "    jet_dict = {}\n",
    "    np.random.seed(seed)\n",
    "    for i,label in enumerate(labels):\n",
    "        jet_dict[label] = np.random.choice(a=df[df[label]==1].j_index, size= int(max_size*ratio[i]),replace=False )\n",
    "    mini_df = pd.DataFrame()\n",
    "    \n",
    "    for label in labels:\n",
    "        mini_df = pd.concat([mini_df,df[df.j_index.isin(jet_dict[label])]],axis=0)\n",
    "    return mini_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadNdownsize (filePath,features,labels,size,seed,ratio=None):\n",
    "    '''\n",
    "    features: 'j_index' is necessary!\n",
    "    '''\n",
    "    with h5py.File(filePath+\"processed-pythia82-lhc13-all-pt1-50k-r1_h022_e0175_t220_nonu_withPars_truth_0.z\", 'r') as f:\n",
    "        treeArray = f['t_allpar_new'][()]\n",
    "    df = pd.DataFrame(treeArray, columns=features+labels) \n",
    "    if ratio==None:\n",
    "        mini_df = downsize(df,size,seed,labels)\n",
    "    else:\n",
    "        mini_df = downsize_unbalanced(df,size,seed,labels,ratio=ratio)\n",
    "    # Add constituents_index\n",
    "    x = [len(list(y)) for _,y in itertools.groupby(mini_df['j_index'])]\n",
    "    j_cIndex = np.array([],dtype='int8')\n",
    "    for i in x:\n",
    "        new_jet_index = np.arange(i)\n",
    "        j_cIndex = np.append(j_cIndex, new_jet_index)\n",
    "    mini_df['constituents_index'] = j_cIndex\n",
    "    _features = features+['constituents_index']\n",
    "    return mini_df, _features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1329098,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########TEST##############\n",
    "filePath = './data/'\n",
    "features = ['j_index','j1_phirel','j1_etarel','j1_phirot','j1_etarot','j1_deltaR','j1_pdgid','j1_ptrel','j1_erel','j_multiplicity'] \n",
    "labels = ['j_g','j_q','j_w','j_z','j_t']\n",
    "with h5py.File(filePath+\"processed-pythia82-lhc13-all-pt1-50k-r1_h022_e0175_t220_nonu_withPars_truth_0.z\", 'r') as f:\n",
    "    treeArray = f['t_allpar_new'][()]\n",
    "    df = pd.DataFrame(treeArray, columns=features+labels)\n",
    "\n",
    "# jet_dict = {}\n",
    "# np.random.seed(42)\n",
    "# for label in labels:\n",
    "#     jet_dict[label] = np.random.choice(a=df[df[label]==1].j_index, size=size,replace=False )\n",
    "# mini_df = pd.DataFrame()\n",
    "# for label in labels:\n",
    "#     mini_df = pd.concat([mini_df,df[df.j_index.isin(jet_dict[label])]],axis=0)\n",
    "df[df['j_t']==1].j_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20136,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########TEST##############\n",
    "np.unique(df[df['j_t']==1].j_index).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2793564    0.000398\n",
       "2793565    0.000382\n",
       "2793566    0.000349\n",
       "2793567    0.000317\n",
       "2793568    0.000276\n",
       "2793569    0.000269\n",
       "2793570    0.000233\n",
       "2793571    0.000165\n",
       "2793572    0.000139\n",
       "2793573    0.000058\n",
       "2949397    0.223644\n",
       "2949398    0.163107\n",
       "2949399    0.123149\n",
       "2949400    0.052711\n",
       "2949401    0.045249\n",
       "2949402    0.035569\n",
       "2949403    0.032382\n",
       "2949404    0.030572\n",
       "2949405    0.022388\n",
       "2949406    0.017231\n",
       "Name: j1_ptrel, dtype: float32"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########TEST##############\n",
    "\n",
    "# Sort constituents by pt in each jet\n",
    "df_sort = pd.DataFrame()\n",
    "cIndex = np.array([],dtype='int8')\n",
    "for i in np.unique(mini_df['j_index']):\n",
    "    df_sort = pd.concat([df_sort,mini_df[mini_df['j_index']==i].sort_values(by=['j1_ptrel'],ascending=False)],axis=0)\n",
    "    new_cIndex = np.arange(mini_df[mini_df['j_index']==i].shape[0])\n",
    "    cIndex = np.append(cIndex, new_cIndex)\n",
    "df_sort['constituents_index'] = cIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadNdownsize (filePath,features,labels,size,seed,ratio=None):\n",
    "    '''\n",
    "    features: 'j_index' is necessary!\n",
    "    '''\n",
    "    with h5py.File(filePath+\"processed-pythia82-lhc13-all-pt1-50k-r1_h022_e0175_t220_nonu_withPars_truth_0.z\", 'r') as f:\n",
    "        treeArray = f['t_allpar_new'][()]\n",
    "    df = pd.DataFrame(treeArray, columns=features+labels) \n",
    "    if ratio==None:\n",
    "        mini_df = downsize(df,size,seed,labels)\n",
    "    else:\n",
    "        mini_df = downsize_unbalanced(df,size,seed,labels,ratio=ratio)\n",
    "    df_sort = pd.DataFrame()\n",
    "    for i in np.unique(mini_df['j_index']):\n",
    "        df_sort = pd.concat([df_sort,mini_df[mini_df['j_index']==i].sort_values(by=['j1_pt'],ascending=False)],axis=0)\n",
    "    return df_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveAsH5(filePath,df, size,features,labels,ratio=None):\n",
    "# Since list is not valid in Dataframe, create a nparray to store the label list\n",
    "    if ratio==None:\n",
    "        label_list = np.vstack([df[label] for label in labels]).T\n",
    "    else:\n",
    "        target = labels[ratio.index(1)]\n",
    "        label_list = np.vstack([df[target], np.abs(df[target]-1)]).T\n",
    "    \n",
    "    if ratio==None:\n",
    "        savePath = filePath+\"data_%sjets_%dlabels\"%(size,len(labels))+'.h5'\n",
    "    else:\n",
    "        savePath = filePath+\"data_%sjets_%dlabels_unbalanced\"%(size,len(labels))+'.h5'\n",
    "        \n",
    "#     if os.path.exists(savePath):\n",
    "#         with h5py.File(savePath, 'r+') as f:\n",
    "#             for col in feats:\n",
    "#                 f[col][()] = df[col]\n",
    "#             f['label'][()] = label_list\n",
    "#     else:\n",
    "#         with h5py.File(savePath, 'w') as f:\n",
    "#             for col in feats:\n",
    "#                 f.create_dataset(col, data=df[col])\n",
    "#             f.create_dataset('label', data = label_list)\n",
    "    with h5py.File(savePath, 'w') as f:\n",
    "            for col in features:\n",
    "                f.create_dataset(col, data=df[col])\n",
    "            f.create_dataset('label', data = label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadTransSave (filePath, features, labels, size, seed,ratio=None):\n",
    "    mini_df = loadNdownsize(filePath,features, labels,size=size,seed=seed,ratio=ratio)\n",
    "    saveAsH5(filePath, df = mini_df, size=size, features=features, labels=labels,ratio=ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = './data/'\n",
    "features = ['index','j1_pt','j1_ptrel','j1_eta','j1_phi','j_mass','j1_pdgid','j1_deltaR','j_multiplicity','j1_etarot','j1_phirot','j_pt','j1_etarel','j1_phirel','j_index']\n",
    "labels = ['j_g','j_q','j_w','j_z','j_t']\n",
    "size=20\n",
    "seed=42\n",
    "ratio=[.25,.25,.25,.25,1]\n",
    "LoadTransSave(filePath,features, labels,size=size,seed=seed,ratio=ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49044 49044 49044 49044 49044 49044 77074 77074 77074 77074]\n",
      "[9.4040769e-01 8.7528598e-01 8.1013715e-01 5.8639365e-01 5.1699448e-01\n",
      " 1.8312424e-02 1.3740416e+02 1.1231701e+02 1.0295010e+02 7.2317307e+01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\Anacoda\\envs\\tf2\\lib\\site-packages\\ipykernel_launcher.py:1: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('data/data_20jets_5labels_unbalanced.h5') as f:\n",
    "    x = f['j_index'][()]\n",
    "    y = f['j1_pt'][()]\n",
    "# print(np.count_nonzero(x == [1,0]))\n",
    "# print(np.count_nonzero(x == [0,1]))\n",
    "print(x[40:50])\n",
    "print(y[40:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
